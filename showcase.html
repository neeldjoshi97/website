<!DOCTYPE HTML>
<!--
	Editorial by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Project Showcase</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="index.html" class="logo"><strong>Personal Website</strong> by Neel Joshi</a>
									<ul class="icons">
										<li><a href="http://www.linkedin.com/in/neeldjoshi" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
										<!-- <li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li> -->
										<li><a href="https://github.com/neeldjoshi97" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<!-- <li><a href="#" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li> -->
									</ul>
								</header>

							<!-- Content -->
								<section>
									<header class="main">
										<h1>Projects</h1>
									</header>

									<span class="image main"><img src="images/project.jpg" alt="" /></span>

									<p>Here are some of the projects I love to share with folks:</p>
									<!-- <p>[_]</p>
									<p>[_]</p> -->
									
									<hr class='major' />
									<h2>Error State Extended Kalman Filter using Observations from CARLA Simulator</h2>
									<p>I coded an Error State Extended Kalman Filter from scratch and tested it on observations (IMU, GNSS and LIDAR) generated using the CARLA Simulator.
									</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/slam_ref.PNG" alt="dt" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/slam_tuned.PNG" alt="dt" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/slam_params.PNG" alt="dt" /></span></div>
										</div>
									</div>
									<p>
										The filter was tuned within 3 sigma limits for 2 adversarial scenarios:
										<br>1. The calibration between the car and the LIDAR sensor frame is miscalculated
										<br>2. Some portion of the trajectory estimation has poor/no GNSS signal e.g. during a tunnel
										</p>

									<hr class="major" />
									<h2>Human Activity Recognition (HAR) using Deep Learning</h2>
									<p>I worked on building and deploying AI models for classifying data from wearable sensors to identify patient gait e.g.
										walking, running, sprinting, sleeping etc. Patients suffering from ACL injury are sent back to their daily activities
										(for rehabilitation) wearing these sensors. Data collected from their movement is analysed to identify their gait and
										for help in medical analysis.</p>
										<p>This included
											<br>1. Reproducing state-of-the-art model archetecures for HAR
											<br>2. Training and testing more than 50 deep learning models
											<br>3. Fine tuning for generalization on unseen data from patients with ICL injury (sparse data - not enough for training)</p>
										<p>This work at the Musculoskeletal Biomechanics Lab was supported by Research Fellowship from CMU.</p>

									<hr class="major" />
									<h2>Digital Twin Simulation of Safety-Critical Scenarios</h2>
									<p>Our project was featured in a Department of Transportation <a href="https://www.youtube.com/watch?v=l84QFbJ4AbQ">video</a> on Cyber Security.</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/digital_twin_1.png" alt="dt" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/digital_twin_2.png" alt="dt" /></span></div>
										</div>
									</div>
									<p>This was inspired by a real life incident in July 2021 when a Tesla owner was driving his car on autopilot. In the evening,
										the moon with a yellowish tinge rose right in front of the car, which the autopilot thought as a yellow traffic light. The car
										kept slowing down till the moon went above its perception horizon. This sounds interesting at first, although this could have
										easily invited safety-critical scenarios e.g. an unbeknownst driver running over from behind. We as a team of 3 replicated this
										exact scenario <b>FOR THE FIRST TIME</b> using state-of-the-art Digital Twin technology and wanted to show that:</p>
										<p> 1) such situation could
										invite safety critical scenarios and <br> 2) using defensive techniques can avoid such adversarial scenarios. We successfully showed
										that <b>98%</b> of such scenarios can be easily avoided using both real-time as well as definitive methods.</p>

										<p>I am grateful to Prof. Ding Zhao for approving my concept for this project and to Wenhao Ding for giving full support throughout the duration of the project.</p>

									<hr class="major" />
									<h2>High Speed Robotic Acuator Inspired from Chamelon Tongue</h2>
									<p>Did you know that a Chameleon can shoot out its tongue upto 2-3 times its body length within a few miliseconds?</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/tongue.jpg" alt="latimes" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/tongue_grasp.JPG" alt="" /></span></div>
										</div>
									</div>
									<p>Above: Chameleon shooting its tongue (left, from LA Times), bioinspired actuator grasping an artificial orange (right)</p>
									<p>The tissues within the tongue act like naturally loaded springs, which produce accelerations in the order of 300 m/s^2 - fastest for any
										living animal species!</p>
									<p>I modelled the dynamics of the tongue as a spring mass system (with two masses each with a spring) with the end mass as the end-effector weight. The end
										mass would change when grasping an object and dragging it back to the base. I was able to decide spring stiffness required for shooting the robotic
										tongue by 2 ft. This was made possible by replicating the telescopic packaging of tissues in the real tongue.</p>
									<p>Future work may involve manufacturing a soft robotic actuator working at high frequency. This could help in factory automation
										with reduced impact while grabbing object. The control of such an actuator will be another equally interesting challenge.</p>

									<hr class="major" />
									<h2>All Terrain Differential Drive with Soft Wheels</h2>
									<p>Soft Robotics is evolving as a promising paradigm of collaborative and sustainable robotics. We as a group of 3 worked on creating a wheeled
										mobile robot with inflatable/deflatable soft wheels. With different levels of inflation/deflation, the robot can take a turn (without a
										differential drive) or run over unequal terrains.</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/inflated.jpg" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/deflated.jpg" alt="" /></span></div>
										</div>
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/wheel_testing.jpg" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/wheel_testing_2.jpg" alt="" /></span></div>
										</div>
									</div>
									<p>Potential applications include driving on challenging terrains like snow, mud, sand; impact reduction mechanism during unavoidable collision;
									 amphibious maneuver, etc.</p>

									<hr class="major" />
									<h2>Feature Matching in Stereo Images using Quasi Dense Feature Propagation Algorithm</h2>
									<p>This was implemented as the final project for the class 'Computer Vision for Engineers'.
										We worked as a team of 4 classmates. We implemented the entire process in parts, each member
										being responsible for one. The final Python script integrates the individual parts of the
										process such that the input of multiple 2D images is processed to output 3D point co-ordinates
										in Polygon File Format which can be imported into any 3D rendering software.</p>
									<p>In case of many images of an object, it becomes difficult to find perfect (seed/sparse)
										keypoints (e.g. SIFT, SURF) which are present in all/most of the images at once. My part was
										concerned about implementing Quasi Dense Matching which uses certain conditions to find out
										neighbouring points of seed keypoints which can be used for triangulation (estimating correct 3D co-ordinates).</p>
									<p>Using the standard Baby image, if one finds the SIFT feature matches in the left and the right image
										(stereo pair) and locate arbitrarily 2 of them like shown (bright red spots):</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/baby_left.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/baby_right.png" alt="" /></span></div>
										</div>
									</div>
									<p>Now after implementing the feature search algorithm, these are all the possible matches one gets with ZNCC threshold of 0.99999:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/baby_left_matched.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/baby_right_matched.png" alt="" /></span></div>
										</div>
									</div>
									<p>Note: <br>
										1. Both the regions have similar shapes <br>
										2. It is evident that each feature point in the left image is mapped to a nearby point in the right image <br>
										3. The red patch (points matched) has a characteristic shape: e.g. 1) notice the holes left at some places where the points
										are not invariant, those are not matched; 2) notice that the red patch keeps its shape according to the lines in the map
										behind the baby (possible reason being that corner points in the map tend to be invariant points). Thus it can be seen that the
										algorithm (although naïve) does its job of matching thousands of key points which will be used for triangulation at the end (depth estimation).</p>

									<p>Because the built-in functions in OpenCV did not have Python bindings, I programmed the whole algorithm from scratch. I used Object Oriented Programming
									knowledge gained from courses at CMU and from online MOOCs to reduce the programming complexity in my implementation. As an example,
									I built a keyPair class to store matched keypoints efficiently and used Heap memory for swift sorting:</p>

									<pre><code>
class keyPair():
	def __init__(self, kp1, kp2, image_1, image_2, window_size, entry_count):
		'''
		Initialiser for class keyPair

		kp1         :co-ordinates of matched keypoint from 1st iamge
		kp2         :co-ordinates of matched keypoints from 2nd image
		image_1     :first image object (numpy array)
		image_2     :second image object (numpy array)
		window_size :for calculating zncc
		entry_count :unique identifier for each 'keyPair' instance
		'''

		# take inputs as type int
		self.u1, self.v1, self.u2, self.v2 = int(kp1[0]), int(kp1[1]), int(kp2[0]), int(kp2[1])
		#--------------------------------#
		assert self.u1 <= image_1.shape[0]
		assert self.u2 <= image_1.shape[0]
		assert self.v1 <= image_1.shape[1]
		assert self.v2 <= image_1.shape[1]
		#--------------------------------#
		self.zncc = zncc(image_1, image_2, self.u1, self.v1, self.u2, self.v2, window_size)
		# self.priority_score = 1.0 - self.zncc
		self.window_size = window_size
		self.entry_count = entry_count

	def __lt__(self, other):
		'''
		Sorting rule for instances of class 'keyPair'
		'''
		# ~ smallest element in heap will have highest zncc
		# return self.priority_score < other.priority_score
		return self.zncc > other.zncc

	def __eq__(self, other):
		'''
		Tie breaker
		'''
		return (self.entry_count == other.entry_count).all()

	def __str__(self):
		'''
		Returns string representation of instance of class 'keyPair'
		'''
		ret_str = '\n--Keypair object consisting 2 matched image co-ordinates--\nEntry no.: ' + \
		str(self.entry_count) + '\n' + 'Window size: ' + str(self.window_size) + '\n' + \
		'keypoint 1: (' + str(self.u1) + ',  ' + str(self.v1) + ')\n' + 'keypoint 2: (' + \
		str(self.u2) + ',  ' + str(self.v2) + ')\n' + 'zncc score: ' + str(self.zncc) + '\n'

		return ret_str

	def getKeypoints(self):
		'''
		Returns 2 numpy arrays containing matched co-ordinates from each image
		'''
		return [np.array([self.u1, self.v1]), np.array([self.u2, self.v2])]
	</code></pre>

									<hr class="major" />
									<h2>Applied Computer Vision</h2>
									<p>Object identification:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/all-parts.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/all-parts-output.png" alt="" /></span></div>
										</div>
									</div>
									<p>Identifying breast cancer:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/x-ray.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/x-ray-color.png" alt="" /></span></div>
										</div>
									</div>
									<p>Edge detection:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/gear.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/gear-canny.png" alt="" /></span></div>
										</div>
									</div>
									<p>Quality improvement:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/pots.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/pots-clean.png" alt="" /></span></div>
										</div>
									</div>
									<p>Scene blending:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/door-stitched.jpg" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/pittsburgh-stitched.jpg" alt="" /></span></div>
										</div>
									</div>
									<p>Crack detection:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/wall2-original.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/wall2-cracks.png" alt="" /></span></div>
										</div>
									</div>
									<p>Fault detection:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/spade-terminal.png" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/spade-terminal-output.png" alt="" /></span></div>
										</div>
									</div>


									<h2>Controller Programming for Autonomous Vehicles Simulation</h2>
									<p>For every CMU student who takes 24-677 Modern Control: Theory and Design, the excitement peaks when they have
										to implement theory acquired in class in actual Python programs. Each student has to program advanced controllers
										for simulating a car (this time it was a Tesla Model 3) to drive safely along a virtual replica of the road which
										runs behind CMU campus. The course instructors race all the cars against each other and declare the top winners.</p>
									<p>While working on vehicle dynamics in simulations, I learned to tune basic PID controller, using both the gains method
										and pole placement; discrete-time infinite horizon LQR controller alongwith A* path planning to maneuver around obstacles
										and Extended Kalman Filter Simultaneous Localization and Mapping (EKF SLAM) to filter observation noise.</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/a_star_3.PNG" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/a_star_2.PNG" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/a_star_1.PNG" alt="" /></span></div>
										</div>
									</div>
									<p><i> <b>When competed against a class of ~65, my programmed car finished in top 8.</b> </i></p>
									<p>Results of EKF SLAM:</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/ekf_1.PNG" alt="" /></span></div>
											<div class="col-4"><span class="image fit"><img src="images/ekf_2.PNG" alt="" /></span></div>
										</div>
									</div>
									<p>For the closing part, I designed a Model Reference Adaptive Controller to study the
										effect of sudden failure in the thrust of a quadrotor mid-air.</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><img src="images/mrac.PNG" alt="" /></span></div>
										</div>
									</div>

									<hr class="major" />
									<h2>Robotic Simulations</h2>
									<p>During the pandemic, I spent my time in learning skills which would help me in my master's education at CMU.
										I started with preliminary reads from websites like Wikipedia and slowly advanced till managing simulations
										in software like CoppeliaSim.</p>
									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><a href="vid3.html"><img src="images/coppelia.PNG" alt="" /></a></span></div>
										</div>
									</div>
									<p><b>Click on the image to view the video</b></p>

									<hr class="major" />
									<h2>Trajectory Optimization and Contact Kinematics</h2>
									<p>The dynamics of robotic systems focus on the mathematical structure of the dynamics and numerical analysis.
										A more formal mathematical framework for kinematics and dynamics should take into account the contact conditions, friction,
										hybrid dynamical systems, timestepping simulation and contact invariant optimization.</p>

									<div class="box alt">
										<div class="row gtr-50 gtr-uniform">
											<div class="col-4"><span class="image fit"><a href="vid1.html"><img src="images/2_link.JPG" alt="" /></a></span></div>
											<div class="col-4"><span class="image fit"><a href="vid2.html"><img src="images/contacts.JPG" alt="" /></a></span></div>
										</div>
									</div>
									<p>The video on the left depicts the trajectory optimization for a 2-link planar mechanism. The video on the right depicts how an agent
										(the red point mass) interacts with the environment following the contact kinematics for each contact.</p>
									<p><b>Click on the image to view the video</b></p>

									<!-- <hr class="major" /> -->

									<!-- <h2>Project 3</h2>
									<p>[_]</p>
									<p>[_]</p> -->

								</section>

						</div>
					</div>

				<!-- Sidebar -->
					<div id="sidebar">
						<div class="inner">

							<!-- Search -->
								<!-- <section id="search" class="alt">
									<form method="post" action="#">
										<input type="text" name="query" id="query" placeholder="Search" />
									</form>
								</section> -->

							<!-- Menu -->
								<nav id="menu">
									<header class="major">
										<h2>Menu</h2>
									</header>
									<ul>
										<li><a href="index.html">Homepage</a></li>
										<li><a href="showcase.html">Showcase</a></li>
										<li><a href="interests.html">Interests</a></li>
										<!-- <li>
											<span class="opener">Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Etiam Dolore</a></li>
										<li><a href="#">Adipiscing</a></li>
										<li>
											<span class="opener">Another Submenu</span>
											<ul>
												<li><a href="#">Lorem Dolor</a></li>
												<li><a href="#">Ipsum Adipiscing</a></li>
												<li><a href="#">Tempus Magna</a></li>
												<li><a href="#">Feugiat Veroeros</a></li>
											</ul>
										</li>
										<li><a href="#">Maximus Erat</a></li>
										<li><a href="#">Sapien Mauris</a></li>
										<li><a href="#">Amet Lacinia</a></li> -->
									</ul>
								</nav>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Recent</h2>
									</header>
									<!-- <div class="mini-posts">
										<article>
											<a href="#" class="image"><img src="images/pic07.jpg" alt="" /></a>
											<p>Something 1</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic08.jpg" alt="" /></a>
											<p>Something 2</p>
										</article>
										<article>
											<a href="#" class="image"><img src="images/pic09.jpg" alt="" /></a>
											<p>Something 3.</p>
										</article>
									</div> -->
									<!-- <ul class="actions">
										<li><a href="#" class="button">More</a></li>
									</ul> -->
								</section>

							<!-- Section -->
								<section>
									<header class="major">
										<h2>Get in touch</h2>
									</header>
									<p></p>
									<ul class="contact">
										<li class="icon solid fa-envelope"><a href="mailto: ndjoshi@andrew.cmu.edu">ndjoshi@andrew.cmu.edu</a></li>
										<li class="icon solid fa-phone">(412) 954-8693</li>
										<!-- <li class="icon solid fa-home">1234 Somewhere Road #8254<br />
										Nashville, TN 00000-0000</li> -->
									</ul>
								</section>

							<!-- Footer -->
								<footer id="footer">
									<p class="copyright">&copy; Untitled. All rights reserved. Demo Images: <a href="https://unsplash.com">Unsplash</a>. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
								</footer>

						</div>
					</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
